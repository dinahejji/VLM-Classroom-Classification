<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <meta name="description" content="VLM Classroom Classification - A Vision-Language Model to classify classroom settings by type and topic." />
  <title>VLM Classroom Classification</title>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet"/>
  <style>
    * {
      box-sizing: border-box;
      margin: 0;
      padding: 0;
      font-family: 'Inter', sans-serif;
    }
    body {
      background-color: #f9fafb;
      color: #1f2937;
      line-height: 1.6;
      padding: 40px;
    }
    header {
      text-align: center;
      margin-bottom: 40px;
    }
    header h1 {
      font-size: 2.5rem;
      margin-bottom: 10px;
    }
    header p {
      font-size: 1.1rem;
      color: #4b5563;
    }
    section {
      max-width: 800px;
      margin: auto;
      padding: 20px;
      background-color: #ffffff;
      border-radius: 12px;
      box-shadow: 0 2px 8px rgba(0,0,0,0.05);
    }
    h2 {
      margin-top: 30px;
      font-size: 1.5rem;
      color: #111827;
    }
    ul {
      margin-top: 10px;
      padding-left: 20px;
    }
    pre {
      background-color: #f3f4f6;
      padding: 10px;
      border-radius: 8px;
      overflow-x: auto;
    }
    a {
      color: #2563eb;
      text-decoration: none;
    }
    a:hover {
      text-decoration: underline;
    }
    iframe {
      border: none;
      border-radius: 10px;
    }
    footer {
      text-align: center;
      margin-top: 40px;
      color: #9ca3af;
    }
    .sub {
      color: #4b5563;
      font-size: 0.95rem;
    }
  </style>
</head>
<body>
  <header>
    <h1>VLM Classroom Classification</h1>
    <p>Vision-Language Model for Classroom Type and Topic Prediction</p>
  </header>

  <section>
    <h2>üìå What is the project?</h2>
    <p>
      VLM Classroom Classification is a multimodal AI system that uses a fine-tuned Vision-Language Model (VLM)
      to classify classroom activities by <strong>scene type</strong> and <strong>academic topic</strong> based on both
      images and transcripts from real teaching environments.
    </p>

    <h2>‚ùì Why does it matter?</h2>
    <p>
      Understanding the type of classroom interaction (e.g., lecture, flipped, lab) and the subject being taught
      is crucial for educational analytics, personalized learning tools, and intelligent tutoring systems.
    </p>

    <h2>‚öôÔ∏è How does it work?</h2>
    <p>
      A VLM (e.g., Qwen2-VL, LLaVA, or BLIP) is fine-tuned on a dataset of annotated classroom images and aligned
      transcripts. Given a new sample, the model processes visual and textual inputs to predict:
    </p>
    <ul>
      <li>Type of class: Lecture, Flipped, Lab, etc.</li>
      <li>Topic: Physics, AI, History, etc.</li>
    </ul>

    <h2>üß™ Methodology</h2>
    <ul>
      <li>Dataset: Curated ~500 classroom images with transcripts + scene descriptions</li>
      <li>Annotation: Human-labeled class types and academic topics</li>
      <li>Training: Using <code>Unsloth</code> with LoRA for parameter-efficient fine-tuning</li>
      <li>Evaluation: Prompt-based inference and visual inspection on unseen samples</li>
    </ul>

    <h2>üìä Results</h2>
    <ul>
      <li>High classification accuracy on clear images and clean transcripts</li>
      <li>Resilience to partial occlusions and noisy classroom audio</li>
      <li>Semantic understanding of student-teacher dialogue context</li>
    </ul>

    <h2>üì∑ Sample Prompt</h2>
    <pre>
### Instruction:
You are a classroom observer. Based on the transcript and image provided, classify:
1. Classroom type (normal lecture, flipped classroom, etc.)
2. Academic topic.

### Transcript:
"Okay, so what does this graph represent? It's the velocity-time graph for motion..."
    </pre>

    <h2>üé¨ Demo</h2>
    <p>Watch a demo of the VLM classifying a real classroom scene using a video + transcript input:</p>
    <div style="margin-top: 20px; text-align: center;">
      <iframe 
        src="https://drive.google.com/file/d/1vUNNUKvRxaSNCshPV-9TzRX2sJe5ePjV/preview" 
        width="100%" height="400" allow="autoplay" allowfullscreen>
      </iframe>
    </div>

    <h2>üåê GitHub</h2>
    <p>
      Repository: <a href="https://github.com/dinahejji/VLM-Classroom-Classification" target="_blank">
        github.com/dinahejji/VLM-Classroom-Classification</a>
    </p>

    <h2>üåü Impact</h2>
    <p>
      This model can serve as a foundation for:
    </p>
    <ul>
      <li>Smart classroom monitoring systems</li>
      <li>Personalized tutoring tools based on activity type</li>
      <li>Large-scale learning analytics in education research</li>
    </ul>

    <h2>üîÆ Future Plans</h2>
    <ul>
      <li>Deploy interactive demo with Gradio or Streamlit</li>
      <li>Enhance robustness to noisy transcripts</li>
      <li>Expand to include audio, quiz results, and gesture analysis</li>
    </ul>
  </section>

  <footer>
    <p>¬© 2025 Dina Hejji ¬∑ <a href="https://github.com/dinahejji" target="_blank">GitHub Profile</a></p>
  </footer>
</body>
</html>
